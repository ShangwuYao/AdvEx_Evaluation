

Robustness score:

We calculate the score by evaluating the accuracy degrade of your model.
Let's say we named the accuracy of the clean dataset to be Original_Accuracy and the accuracy of attack methods to be Attack_Accuracy, then the formula is the average of (Original_Accuracy-Attack_Accuracy)/Original_Accuracy.
If the attack doesn't affect you model, which means the Attack_Accuracy is nearly the same as the Original_Accuracy, then the score should be close to zero. Therefore, as you can imagine, the lower the score, the better.

Confidence:

Confidence represents how confident is your model when it makes a prediction. Here we simply interpret the output of the final softmax layer as a probability distribution, and takes the score after softmax layer to be the confidence. 

